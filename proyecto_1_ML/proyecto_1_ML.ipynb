{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1: Identificando números con imágenes\n",
    "En este ejercicio analizaras e identificarás números dados en la forma de imagen. Para ello puedes utilizar tu solución preferida identificar grupos de imágenes similares. Por ejemplo, puedes aplicar reducción de dimensionalidad antes o después del entrenamiento, puedes también elegir no usarlo. Para hacer la predicción puedes hacer uso de un método de agrupamiento y resolver la tarea con aprendizaje no supervisado, o puedes utilizar un algoritmo de clasificación y elegir el camino de aprendizaje supervisado.\n",
    "\n",
    "A diferencia de los ejercicios anteriores donde programaste las soluciones analíticas a los métodos de ML, en este proyecto se recomienda el uso de las funciones y clases integradas de scikit-learn. Para entender el uso de estas clases y ver algunos ejemplos puedes consultar la documentación oficial\n",
    "- [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "- [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE)\n",
    "- [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "- [DBScan](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)\n",
    "- [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "En este proyecto tendrás que elegir que método de reducción de dimensionalidad y que método de agrupamiento deseas aplicar a tus datos. Es tu trabajo analizar la información dada para tomar estas decisiones. Lee con atención todas las instrucciones y celdas de código, y recuerda agregar tu código en todas las partes donde veas la instrucción \"`TODO`\"\n",
    "\n",
    "## Descripción\n",
    "Tu trabajo es identificar grupos en imágenes para reconocimiento de números. Para esto, deberás realizar los siguientes pasos:\n",
    "1. Dado que nuestros datos están en diferentes escalas, es necesario normalizar los datos.\n",
    "2. Aplicar un método de reducción de dimensionalidad y visualizar los datos\n",
    "3. Buscar grupos en los datos reducidos con alguna técnica de agrupamiento o clasificación.\n",
    "4. Interpretar los resultados.\n",
    "5. Dadas dos imágenes nuevas, identificar a que grupo pertenece. (Inferencia)\n",
    "\n",
    "Nota como existen múltiples soluciones a este problema. La decisión de como resolverlo es tuya (: intenta hacerlo lo mejor posible!\n",
    "Comenzamos por importar las librerías correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Analizando los datos\n",
    " Comenzamos leyendo nuestros datos y visualizando algunos ejemplos para analizarlos. En este caso utilizaremos el [digits dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html#sphx-glr-auto-examples-datasets-plot-digits-last-image-py). En este dataset encontrarás 1797 imágenes de 8x8. Cada imagen es un dígito escrito a mano. Primero separaremos los datos en entrenamiento y validación\n",
    "\n",
    " Recuerda! los datos de entranmiento *son los únicos* que puedes usar para entrenar tus modelos. El conjunto de validación solo se utilizará para evaluar el rendimiento de los modelos que elijas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos nuestros datos y los separamos en entrenamiento y validación\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "\n",
    "# El 25% de los datos se asignará aleatoriamente a validación\n",
    "data_train, data_val, target_train, target_val = train_test_split(\n",
    "    data, \n",
    "    labels, \n",
    "    test_size=0.25\n",
    ")\n",
    "print(f\"Imágenes en rango {np.max(data)}, {np.min(data)}\")\n",
    "\n",
    "# Entrenamiento\n",
    "(n_samples, n_features), n_digits = data_train.shape, np.unique(target_train).size\n",
    "print(f\"# Dígitos: {n_digits}; # Muestras de entrenamiento: {n_samples}; # Variables {n_features}\")\n",
    "\n",
    "# Validación\n",
    "(n_samples, n_features), n_digits = data_val.shape, np.unique(target_val).size\n",
    "print(f\"# Dígitos: {n_digits}; # Muestras de validación: {n_samples}; # Variables {n_features}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio las imágenes se entregan como un vector de 64 variables, donde cada elemento corresponde al valor de un pixel. Para visualizar los datos en forma de imagen, es necesario transformarlos a la forma adecuada. En las siguiente celda puedes ver algunas imágenes de ejemplo, así como la forma en que podemos transformar el vector de variables a una matriz de 8x8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "\n",
    "# Visualizar algunas imágenes\n",
    "n_cols = 3\n",
    "idx = np.random.randint(len(data_train), size=n_cols)\n",
    "fig, axes = plt.subplots(1, n_cols, figsize=(6,3))\n",
    "axes = axes.flatten()\n",
    "for ax, i in zip(axes, idx):\n",
    "    side = np.sqrt(len(data_train[i])).astype('int')\n",
    "    # La imagen está dada como un solo vector de longitud 64\n",
    "    # Cambiamos la forma para tenerla en forma de imagen de 8x8 pixeles\n",
    "    img = data[i].reshape((side, side))\n",
    "    ax.matshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Etiqueta: {labels[i]}\")\n",
    "fig.suptitle(\"Ejemplos de muestras de entrenamiento\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización en baja dimensionalidad\n",
    "En la siguiente celda puedes visualizar como se ven tus datos reduciendo la dimensionalidad de 30 variables a 2. Explora usar TSNE y PCA, y elige el que te de mejor información.\n",
    "\n",
    "Considera que durante inferencia, siempre trabajaremos con los datos de validación exclusivamente y solo se utilizarán los de entrenamiento para entrenar.\n",
    "\n",
    "¿Cual método de reducción de dimensionalidad funciona mejor en este caso?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Reducimos la dimensionalidad de los datos DE VALIDACIÓN data_val\n",
    "# a 2 dimensiones usando TSNE y/o PCA\n",
    "reduced_data_val = \n",
    "\n",
    "labels = np.unique(target_train)\n",
    "fig, ax_pca = plt.subplots(1, 1, figsize=(4,4))\n",
    "fig.suptitle(\"Puntos reducidos a dos dimensiones\")\n",
    "for c in labels:\n",
    "    indices = np.where(target_train == c)\n",
    "    plot_data = reduced_data_val[indices]\n",
    "    ax_pca.scatter(plot_data[:, 0], plot_data[:, 1], label=f\"Grupo {c}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la imagen anterior, explica detalladamente que información nos da sobre el dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Funciones de utilidad\n",
    "En la siguiente sección definimos algunas funciones que podrías llegar a necesitar. Esto depende completamente de cómo decidas implementar tu algoritmo. Lee la descripción de las siguientes funciones y determina si las necesitas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBScan no tiene una definición para predecir nuevos datos,\n",
    "# puedes usar el siguiente código para hacer inferencia con dbscan\n",
    "import scipy as sp\n",
    "def dbscan_predict(dbscan_model, X_new, metric=sp.spatial.distance.cosine):\n",
    "    # Result is noise by default\n",
    "    y_new = np.ones(shape=len(X_new), dtype=int)*-1 \n",
    "    # Iterate all input samples for a label\n",
    "    for j, x_new in enumerate(X_new):\n",
    "        # Find a core sample closer than EPS\n",
    "        for i, x_core in enumerate(dbscan_model.components_): \n",
    "            if metric(x_new, x_core) < dbscan_model.eps:\n",
    "                # Assign label of x_core to x_new\n",
    "                y_new[j] = dbscan_model.labels_[dbscan_model.core_sample_indices_[i]]\n",
    "                break\n",
    "    return y_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tu turno!\n",
    "Datos los datos `data_train` con las etiquetas `target_train` define y entrena un algoritmo que identifique dígitos. Puedes utilizar tu método preferido. Utiliza las librerías de scikit learn. En la sección de abajo encontrarás un código que puedes usar para probar tu algoritmo. Agrega el código necesario en el método de `mi_modelo` para entrenar el modelo que decidas usar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de agrupamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos la normalización de datos.\n",
    "# Comó validación debe estar completamente disjunto de entrenamiento\n",
    "# Seleccionamos los valores de normalización usando los datos de entrenamiento\n",
    "# y aplicamos la misma normalización a ambos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_train)\n",
    "\n",
    "def mi_modelo(X, label):\n",
    "    '''\n",
    "        args:\n",
    "            - X (nd.array): Arreglo de dimensionalidad (N, D) donde D=64 conteniendo las imágenes en forma de vector\n",
    "            - label (nd.array, tipo int): Arreglo de dimensionalidad (N,) conteniendo las etiquetas de clase/grupo para cada imagen\n",
    "        returns:\n",
    "            - model (object): Instancia de clase del modelo entrenado en los datos X normalizados\n",
    "    '''\n",
    "    # Normalizamos los datos de entrenamiento\n",
    "    data = scaler.transform(X)\n",
    "\n",
    "    # TODO: Entrena el modelo y regresa el modelo entrenado en los datos de entrenamiento.\n",
    "    # Entrena tu modelo con los DATOS NORMALIZADOS\n",
    "\n",
    "    return model\n",
    "\n",
    "def mi_inferencia(modelo, X_val):\n",
    "    '''\n",
    "        args:\n",
    "            - modelo(object): Instancia de la clase del modelo que estés utilizando\n",
    "            - X_val(np.ndarray): Arreglo de dimensionalidad (N, D) donde D=64 conteniendo las imágenes en forma de vector\n",
    "        returns:\n",
    "            - preds(np.ndarray, tipo int): Arreglo de dimensionalidad (N,) conteniendo las predicciones de clase/grupo para cada imagen\n",
    "    '''\n",
    "    # Normalizamos los datos de validación\n",
    "    # El mismos preprocesamiento de datos se aplica a\n",
    "    # tanto inferencia como entrenamiento\n",
    "    data = scaler.transform(X_val)\n",
    "\n",
    "    # TODO: Utiliza el modelo para predecir valores para los datos de validación\n",
    "    # Regresa las predicciones de tu modelo para X_val.\n",
    "    # Aplica inferencia sobre los DATOS NORMALIZADOS\n",
    "    \n",
    "    return preds\n",
    "\n",
    "# Utilizamos solo los datos de entrenamiento (alta dimensionalidad) para entrenar\n",
    "modelo = mi_modelo(data_train, target_train)\n",
    "\n",
    "# Utilizamos los datos de validacion (alta dimensionalidad) para hacer inferencia\n",
    "# con el modelo entrenado\n",
    "pred = mi_inferencia(modelo, data_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluación y análisis de las predicciones\n",
    "En esta sección incluimos funciones que te permiten visualizar la predicción de tu modelo para el set de validación. Dado que nuestros datos son de alta dimensionalidad (64) necesitamos reducirlos para poder analizar las predicciones. Recuerda que en esta sección solo funcionará si has definido tu modelo correctamente en el método anterior `mi_modelo`. Recuerda que en esta sección nos interesa mostar el rendimiento del modelo en los datos de *validación*.\n",
    "\n",
    "## 4.1 (Inferencia) Predicciones en baja dimensionalidad\n",
    "\\# TODO:\n",
    "\n",
    "Diseña un programa tal que puedas visualizar **las predicciones de TU modelo** de el dataset de validación en baja dimensionalidad. \n",
    "- Utiliza el método de reducción de dimensionalidad que consideres te ayude mejor a analizar tus datos. \n",
    "- Cada clase/grupo deberá mostrarse en un color diferente.\n",
    "- Además de visualizar las predicciones, visualiza las predicciones **correctas**\n",
    "- Puedes basarte en el código al inicio del notebook para mostrar los puntos o en los ejercicios pasados.\n",
    "- Revisa el pdf adjunto tal que observes cómo deberías presentar tus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a inferencia de su modelo\n",
    "# preds deberá ser de la forma N,1\n",
    "# indicando el número al que corresponde cada imagen\n",
    "preds = mi_inferencia(modelo, data_val)\n",
    "\n",
    "# Buscamos la cantidad de grupos/clases que hay en los datos de validación\n",
    "group_pred = np.unique(preds)\n",
    "n_groups = len(group_pred)\n",
    "print(f\"Datos {data_val.shape}, predicciones {preds.shape}, clases/grupos {n_groups}\")\n",
    "\n",
    "fig, ax_reduced = plt.subplots(1, 1, figsize=(4,4))\n",
    "fig.suptitle(\"Puntos clasificados reducidos a dos dimensiones\")\n",
    "\n",
    "# TODO: Grafíca los datos DE VALIDACIÓN reducidos (reduced_data_val)\n",
    "# con un color distinto para cada grupo/clase que tu modelo ha predecido (preds)\n",
    "#========== Start =========\n",
    "\n",
    "#========== End ===========\n",
    "plt.show()\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 (Inferencia) Visualizar imagenes en cada grupo/clase\n",
    "Completa el código de la siguiente celda. El siguiente código llama al método de inferencia anteriormente definido. Deberás mostrar al menos 1 imagen por cada grupo de predicción de tu modelo. Puedes intentar seleccionar una imagen representativa del grupo, o también puedes mostrar n imágenes aleatorias por cada grupo/clase. El objetivo de esto es analizar lo que ha aprendido tu modelo.\n",
    "\n",
    "#### Métodos de clasificación\n",
    "Si utilizaste un método de clasificación multiclase, los esperable sería que el valor real de la muestra (GT) sea igual al valor de la predicción para al menos la mayoría de los casos.\n",
    "\n",
    "#### Métodos de agrupamiento\n",
    "Si utilizaste un algoritmo de agrupamiento, es esperable que el valor real de la muestra (GT) no sea igual al grupo de tu predicción. Recuerda que al ser aprendizaje no supervisado, necesitamos adicionalmente \"mapear\" los grupos que haya encontrado el algoritmo a los reales. Puedes usar esta sección para hacer dicho mapeo. Lo mas sencillo es usar un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a inferencia de su modelo\n",
    "# Este método regresará las clases/grupos\n",
    "# que haya encontrado para cada punto de validación\n",
    "preds = mi_inferencia(modelo, data_val)\n",
    "\n",
    "# Clases/grupos distintos de predicciones\n",
    "group_pred = np.unique(preds)\n",
    "n_groups = len(group_pred)\n",
    "\n",
    "# Graficar\n",
    "n_cols = 5\n",
    "fig, axes = plt.subplots(n_groups//n_cols, n_cols, figsize=(10,6))  # Puedes cambiar o eliminar esta linea si lo consideras necesario.\n",
    "axes = axes.flatten() # Convertir los axes a lista para poder iterarlos\n",
    "# TODO: Muestra una imagen por cada grupo/clase de preddicion\n",
    "#========== Start =========\n",
    "#========== End ===========\n",
    "fig.suptitle(\"Muestras representativas por grupo\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 (Inferencia) Calculando el accuracy\n",
    "En la siguiente celda calcula una métrica (un valor numérico) para TODO el conjunto de validación donde indiques cuantas muestras en promedio clasifica tu modelo correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = data_val\n",
    "etiquetas = target_val\n",
    "preddicciones = mi_inferencia(modelo, datos)\n",
    "\n",
    "# TODO: Calcula el \"accuracy\" promedio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a lo que puedes observar en las celdas anteriores de esta sección, responde:\n",
    "- ¿Consideras que tu algoritmo ha aprendido algo que tiene sentido?\n",
    "- ¿Qué aprendió tu modelo?\n",
    "- ¿Cómo podrías generar una métrica para evaluar el rendimiento en validación?\n",
    "- ¿Cuál es el rendimiento de tu modelo en validación? (De preferencia proporciona un número y analízalo)\n",
    "- ¿En que situaciones falla?\n",
    "- ¿A que crees que se deba esto?\n",
    "- ¿Cómo podrías mejorarlo?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistemas_inteligentes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04dc998fdd71cb65825f35fa039c285a87c761883882ab18ec8c9090ce63cd9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
