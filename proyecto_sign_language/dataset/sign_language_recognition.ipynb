{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<center>Recognizing American Sign Language</center>**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://miro.medium.com/max/696/0*vmgQDtKZthpE9Fel\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are aware, human interaction is affected by various health issues, and one such issue is deafness. With the advancement of Artificial Intelligence, we are witnessing the emergence of several solutions. In this notebook, our objective is to develop a Deep Learning model using the CNN Algorithm. This model is a crucial step in addressing the communication challenges caused by deafness.\n",
    "\n",
    "### ***Note 1:***\n",
    "The dataset used in this project consists of 25 labels instead of 26. This is because the letters 'J' and 'Z' require hand gestures for understanding. However, the dataset creator may have considered that the letter 'Z' has a distinctive appearance and can be easily identified. Hence, the dataset includes the letter 'Z' but excludes the letter 'J'.\n",
    "### ***Note 2:***\n",
    "It should be noted that this dataset contains a few incorrect labels. While the model rarely misclassifies images, the accuracy of the labeling can be confirmed by comparing it to the correct labeling mentioned below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Installing the Required Libraries**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you have not installed the required libraries, you can do so by running the following code. If you already have the libraries installed, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3  install numpy\n",
    "!pip3  install pandas\n",
    "!pip3  install seaborn\n",
    "!pip3  install matplotlib\n",
    "!pip3  install pytorch\n",
    "!pip3  install sklearn\n",
    "!pip3  install mlxtend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra,math functions\n",
    "import tensorflow as tf # tensorflow\n",
    "import random # for seed value\n",
    "import os # for folder functions\n",
    "import string # for making alphabet labels as string\n",
    "import pandas as pd # data processing\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # data visualization\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'): # default\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# We are using random seeds for controlling randomness."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:/Users/xjont/OneDrive/Documentos/CETYS/6TO SEMESTRE/SISTEMAS INTELIGENTES/REPOSITORY/SI23-BongoCat/proyecto_sign_language/dataset/sign_mnist_train/sign_mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/xjont/OneDrive/Documentos/CETYS/6TO SEMESTRE/SISTEMAS INTELIGENTES/REPOSITORY/SI23-BongoCat/proyecto_sign_language/dataset/sign_mnist_test/sign_mnist_test.csv\")\n",
    "print(\"Shape of train_data: \",train_data.shape,\"Shape of test_data: \",test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strlabels=list(string.ascii_uppercase) # Appending alphabet to a list.\n",
    "strlabels.remove(\"J\") # Removing J letter because of the hand gesture problem.\n",
    "print(strlabels) # Making a new list that contains letters for each indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=train_data[\"label\"]\n",
    "train_images=train_data.drop(\"label\",axis=1).values # Dropping labels axis=1 > all column (axis=0 is all row)\n",
    "test_labels=test_data[\"label\"]\n",
    "test_images=test_data.drop(\"label\",axis=1).values # Dropping Labels axis=1 > all column (axis=0 is all row)\n",
    "                                               \n",
    "train_images=train_images/255.0 # We are scaling our pixels between 0 and 1 for the sake of computing performance.\n",
    "test_images=test_images/255.0\n",
    "\n",
    "train_images=train_images.reshape(-1,28,28,1) # Reshaping for making images ready to go.\n",
    "test_images=test_images.reshape(-1,28,28,1)\n",
    "print(train_images.shape) # We have 27.455 images as 28x28x1 (2D Image with one channel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load of 8 examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure() # Matplotlib for visualization.\n",
    "f, graph = plt.subplots(2,4) # Making space for 2 rows and 4 images for each row.\n",
    "f.set_size_inches(14, 5) # Size of images.\n",
    "z=0\n",
    "for i in range(2): # i for rows\n",
    "    for k in range(4): # k for columns\n",
    "        graph[i][k].imshow(train_images[z].reshape(28,28),cmap=\"gray\") # Showing each train image.\n",
    "        graph[i][k].grid(False) # Removing grids for each train image.\n",
    "        z+=1\n",
    "plt.tight_layout() # Wide space for images.\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building the CNN**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building the CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([ # Using tf.keras for build our sequential.\n",
    "    tf.keras.layers.Conv2D(64,(3,3),padding=\"same\",activation=\"relu\",input_shape=(28,28,1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D((2,2),strides=2),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.2), # Dropping random 2% data out for learning variety.\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32,(3,3),padding=\"same\",activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D((2,2),strides=2),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(16,(3,3),padding=\"same\",activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(25,activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "model.summary() # Summary of our model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "generator.fit(train_images)\n",
    "# We use ImageDataGenerator for changing images randomly and train our model better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_treshold = 1.0 # Accuracy treshold.\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    epc=0\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc') >= acc_treshold-0.005 and logs.get('val_acc') >= acc_treshold):\n",
    "            print(\"\\nReached %2.2f%% accuracy !\" %(logs.get('val_acc')*100)) # Printing accuracy as percentage.\n",
    "            self.model.stop_training = True\n",
    "            self.epc=epoch+1\n",
    "callbacks = myCallback()\n",
    "# We are using callbacks because we want to shut our training process down when it learns 100%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training the CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "epochs=80\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "history=model.fit(generator.flow(train_images,train_labels,batch_size),epochs=epochs,callbacks=[callbacks],validation_data=(test_images,test_labels),verbose=1)\n",
    "# generator.flow() for applying data augmentation.\n",
    "test_loss,test_acc=model.evaluate(test_images,test_labels)\n",
    "print(\"test acc:\",test_acc)\n",
    "\n",
    "epoch_range=range(1,callbacks.epc+1 if callbacks.epc != 0 else epochs) # Epoch range for plotting our x-axis.\n",
    "plt.figure() # Matplotlib for visualization.\n",
    "f, ax = plt.subplots(1,2) # Making space for 2 rows and 4 images for each row.\n",
    "fig.set_size_inches(30, 5) # Size of images.\n",
    "plt.tight_layout() # Wide space for images.\n",
    "ax[0].plot(epoch_range,history.history[\"acc\"],color=\"blue\",marker=\"o\")\n",
    "ax[0].plot(epoch_range,history.history[\"val_acc\"],color=\"orange\",marker=\"o\")\n",
    "ax[0].legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
    "ax[1].plot(epoch_range,np.array(history.history[\"loss\"]),color=\"blue\",marker=\"o\")\n",
    "ax[1].plot(epoch_range,np.array(history.history[\"val_loss\"]),color=\"orange\",marker=\"o\")\n",
    "ax[1].legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inference of the CNN**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can test our CNN model with a random image from the test set. We can see that the model is able to predict the correct label for the image. We can also see the confidence score for the prediction. The confidence score is the probability of the image belonging to the predicted class. In this case, the confidence score is 1.0, which means that the model is 100% confident that the image belongs to the predicted class. This is because the model is trained on a small dataset and the image is from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "n = int(random.randint(1,25))\n",
    "plt.imshow(test_images[n].reshape(28,28),cmap=\"gray\") # Showing images\n",
    "plt.grid(False) # Removing grid for each image.\n",
    "print(\"Predicted:\",predictions[n],\"\\nLabel:\",test_labels_string[n]) # Prediction - True Answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistemas_inteligentes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
